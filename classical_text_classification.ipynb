{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@author : https://github.com/nitish11  \n",
    "#@decription : finding relationship betwen two sentences \n",
    "#@date : 31st June, 2017'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective : \n",
    "\n",
    "* Text classification for given two columns of data *train_data[[1,2]]*.\n",
    "* No. of classes = 5 *[' ForwardEntailment', ' Independent', ' Equivalence', ' ReverseEntailment', ' OtherRelated']*\n",
    "\n",
    "* Other columns contain extra  information about the two segments of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach \n",
    "\n",
    "### Using classical method of classification\n",
    "\n",
    "* Preprcoessing of columns of the given data\n",
    "    * Extract the numeral information from the data given as extra columns\n",
    "    * Store only these columns as training data\n",
    "* Use the extracted information from training data and perform classical methods (Random Forest, XGboost) for classification. \n",
    "\n",
    "\n",
    "### Deep Learning Solution \n",
    "\n",
    "* Use only starting 2 columns (text_data) and do pre-processing.\n",
    "* Use word2vec or Glove for representing text as vectors.\n",
    "* Use the vectors and do classiication using differen models as LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data and preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('-- keys : ', Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], dtype='int64'))\n",
      "('---text_data:',                  1                     2\n",
      "0   used to treat              to treat \n",
      "1    education is    education programs \n",
      "2    are reviewed      are under review )\n",
      "('--- Results :', array([' ForwardEntailment', ' Independent', ' Equivalence',\n",
      "       ' ReverseEntailment', ' OtherRelated'], dtype=object))\n",
      "('--- #of rows:', 1000)\n"
     ]
    }
   ],
   "source": [
    "#Loading training data\n",
    "ppdb_train_data = pd.read_csv(\"ppdb.train.csv\", header=None, sep=',')\n",
    "\n",
    "print(\"-- keys : \",ppdb_train_data.keys())\n",
    "print(\"---text_data:\",ppdb_train_data[[1,2]].head(3))\n",
    "print(\"--- Results :\",ppdb_train_data[17].unique())\n",
    "print(\"--- #of rows:\",len(ppdb_train_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "0 : [VP/NP] \n",
      "1 :  used to treat \n",
      "2 :  to treat \n",
      "3 :  PPDB2.0Score=4.76476 PPDB1.0Score=12.744950 -logp(LHS\n",
      "4 : e1)=0.30786 -logp(LHS\n",
      "5 : e2)=0.89456 -logp(e1\n",
      "6 : LHS)=14.95995 -logp(e1\n",
      "7 : e2)=7.90234 -logp(e1\n",
      "8 : e2,LHS)=6.75647 -logp(e2\n",
      "9 : LHS)=12.48692 -logp(e2\n",
      "10 : e1)=4.84261 -logp(e2\n",
      "11 : e1,LHS)=4.28343 AGigaSim=0.80561 Abstract=0 Adjacent=0 CharCountDiff=-5 CharLogCR=-0.48551 ContainsX=0 Equivalence=0.088485 Exclusion=0.047945 GlueRule=0 GoogleNgramSim=0.33742 Identity=0 Independent=0.133904 Lex(e1\n",
      "12 : e2)=63.30685 Lex(e2\n",
      "13 : e1)=63.30685 Lexical=1 LogCount=0 MVLSASim=NA Monotonic=1 OtherRelated=0.018057 PhrasePenalty=1 RarityPenalty=0.01832 ForwardEntailment=0.711609 SourceTerminalsButNoTarget=0 SourceWords=3 TargetComplexity=0.97133 TargetTerminalsButNoSource=0 TargetWords=2 UnalignedSource=0 UnalignedTarget=0 WordCountDiff=-1 WordLenDiff=-0.16667 WordLogCR=-0.40547 \n",
      "14 : nan\n",
      "15 : nan\n",
      "16 :  0-0 1-0 2-1 \n",
      "17 :  ForwardEntailment\n"
     ]
    }
   ],
   "source": [
    "#Displaying one data-point \n",
    "print \"-\"*80\n",
    "for key in ppdb_train_data.columns:\n",
    "    print key,\":\", ppdb_train_data.iloc[0][key]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusing data points \n",
    "\n",
    "#### Reference : the above columns \n",
    "\n",
    "* Columns 4th, 5th, 6th, 7th, 8th, 9th and 10th are very confusing and not making sense.\n",
    "* I think there is an issue in making this csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training_data preparation \n",
    "columns = [\"text_type\",\"ppdb1_score\",\"ppdb2_score\", \"logp_lhs_e1\", \"logp_lhs_e2\", \"logp_e1_lhs\", \n",
    "           \"logp_e2_lhs\", \"logp_e1_e2\", \"logp_e1_e2_lhs\", \"logp_e2_e1\", \"logp_e2_e1_lhs\",\n",
    "           \"AGigaSim\", \"GoogleNgramSim\", \"result\"]\n",
    "\n",
    "#Creating blank dataframe\n",
    "dummy_data = np.random.randn(len(ppdb_train_data.index),len(columns))\n",
    "train_data = pd.DataFrame(dummy_data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ppdb1_score</th>\n",
       "      <th>ppdb2_score</th>\n",
       "      <th>logp_lhs_e1</th>\n",
       "      <th>logp_lhs_e2</th>\n",
       "      <th>logp_e1_lhs</th>\n",
       "      <th>logp_e2_lhs</th>\n",
       "      <th>logp_e1_e2</th>\n",
       "      <th>logp_e1_e2_lhs</th>\n",
       "      <th>logp_e2_e1</th>\n",
       "      <th>logp_e2_e1_lhs</th>\n",
       "      <th>AGigaSim</th>\n",
       "      <th>GoogleNgramSim</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.483986</td>\n",
       "      <td>0.408002</td>\n",
       "      <td>0.767297</td>\n",
       "      <td>0.435509</td>\n",
       "      <td>0.232661</td>\n",
       "      <td>-0.946388</td>\n",
       "      <td>0.228995</td>\n",
       "      <td>0.914758</td>\n",
       "      <td>-0.03176</td>\n",
       "      <td>0.435317</td>\n",
       "      <td>-1.280009</td>\n",
       "      <td>-0.624575</td>\n",
       "      <td>0.894714</td>\n",
       "      <td>-0.004533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.631244</td>\n",
       "      <td>-0.518553</td>\n",
       "      <td>-1.425335</td>\n",
       "      <td>0.531890</td>\n",
       "      <td>0.052497</td>\n",
       "      <td>-0.561156</td>\n",
       "      <td>1.401802</td>\n",
       "      <td>0.440235</td>\n",
       "      <td>0.33699</td>\n",
       "      <td>0.173777</td>\n",
       "      <td>-0.029438</td>\n",
       "      <td>2.251837</td>\n",
       "      <td>-0.127533</td>\n",
       "      <td>-0.582025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_type  ppdb1_score  ppdb2_score  logp_lhs_e1  logp_lhs_e2  logp_e1_lhs  \\\n",
       "0  -0.483986     0.408002     0.767297     0.435509     0.232661    -0.946388   \n",
       "1   0.631244    -0.518553    -1.425335     0.531890     0.052497    -0.561156   \n",
       "\n",
       "   logp_e2_lhs  logp_e1_e2  logp_e1_e2_lhs  logp_e2_e1  logp_e2_e1_lhs  \\\n",
       "0     0.228995    0.914758        -0.03176    0.435317       -1.280009   \n",
       "1     1.401802    0.440235         0.33699    0.173777       -0.029438   \n",
       "\n",
       "   AGigaSim  GoogleNgramSim    result  \n",
       "0 -0.624575        0.894714 -0.004533  \n",
       "1  2.251837       -0.127533 -0.582025  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Unique Results :  [' ForwardEntailment' ' Independent' ' Equivalence' ' ReverseEntailment'\n",
      " ' OtherRelated']\n",
      " Equivalence          303\n",
      " ReverseEntailment    301\n",
      " Independent          212\n",
      " ForwardEntailment    176\n",
      " OtherRelated           8\n",
      "Name: 17, dtype: int64\n",
      "-- Updated Results :  [ 0.  1.  2.  3.  4.]\n",
      "2.0    303\n",
      "3.0    301\n",
      "1.0    212\n",
      "0.0    176\n",
      "4.0      8\n",
      "Name: result, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing of result column\n",
    "print \"-- Unique Results : \",ppdb_train_data[17].unique()\n",
    "print pd.value_counts(ppdb_train_data[17])\n",
    "\n",
    "for index,element in enumerate(ppdb_train_data[17].unique()):\n",
    "    indices = ppdb_train_data[ppdb_train_data[17] == element].index.tolist()\n",
    "    train_data.loc[indices, \"result\"] = index\n",
    "\n",
    "print \"-- Updated Results : \",train_data[\"result\"].unique()\n",
    "print pd.value_counts(train_data[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Processing of 0th column\n",
    "# print \"---\"*30\n",
    "# print pd.value_counts(ppdb_train_data[0])\n",
    "for index,element in enumerate(ppdb_train_data[0].unique()):\n",
    "    indices = ppdb_train_data[ppdb_train_data[0] == element].index.tolist()\n",
    "    train_data.loc[indices, \"text_type\"] = index\n",
    "\n",
    "# print \"---\"*30\n",
    "# print pd.value_counts(train_data[\"text_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ppdb1_score</th>\n",
       "      <th>ppdb2_score</th>\n",
       "      <th>logp_lhs_e1</th>\n",
       "      <th>logp_lhs_e2</th>\n",
       "      <th>logp_e1_lhs</th>\n",
       "      <th>logp_e2_lhs</th>\n",
       "      <th>logp_e1_e2</th>\n",
       "      <th>logp_e1_e2_lhs</th>\n",
       "      <th>logp_e2_e1</th>\n",
       "      <th>logp_e2_e1_lhs</th>\n",
       "      <th>AGigaSim</th>\n",
       "      <th>GoogleNgramSim</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408002</td>\n",
       "      <td>0.767297</td>\n",
       "      <td>0.435509</td>\n",
       "      <td>0.232661</td>\n",
       "      <td>-0.946388</td>\n",
       "      <td>0.228995</td>\n",
       "      <td>0.914758</td>\n",
       "      <td>-0.03176</td>\n",
       "      <td>0.435317</td>\n",
       "      <td>-1.280009</td>\n",
       "      <td>-0.624575</td>\n",
       "      <td>0.894714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.518553</td>\n",
       "      <td>-1.425335</td>\n",
       "      <td>0.531890</td>\n",
       "      <td>0.052497</td>\n",
       "      <td>-0.561156</td>\n",
       "      <td>1.401802</td>\n",
       "      <td>0.440235</td>\n",
       "      <td>0.33699</td>\n",
       "      <td>0.173777</td>\n",
       "      <td>-0.029438</td>\n",
       "      <td>2.251837</td>\n",
       "      <td>-0.127533</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_type  ppdb1_score  ppdb2_score  logp_lhs_e1  logp_lhs_e2  logp_e1_lhs  \\\n",
       "0        0.0     0.408002     0.767297     0.435509     0.232661    -0.946388   \n",
       "1        1.0    -0.518553    -1.425335     0.531890     0.052497    -0.561156   \n",
       "\n",
       "   logp_e2_lhs  logp_e1_e2  logp_e1_e2_lhs  logp_e2_e1  logp_e2_e1_lhs  \\\n",
       "0     0.228995    0.914758        -0.03176    0.435317       -1.280009   \n",
       "1     1.401802    0.440235         0.33699    0.173777       -0.029438   \n",
       "\n",
       "   AGigaSim  GoogleNgramSim  result  \n",
       "0 -0.624575        0.894714     0.0  \n",
       "1  2.251837       -0.127533     1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index,element in enumerate(ppdb_train_data[3]):\n",
    "    ppdb1 = element.split('=')[2].split(' ')[0]\n",
    "    ppdb2 = element.split('=')[1].split(' ')[0]\n",
    "    train_data.loc[index, \"ppdb1_score\"] = ppdb1\n",
    "    train_data.loc[index, \"ppdb2_score\"] = ppdb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ppdb1_score</th>\n",
       "      <th>ppdb2_score</th>\n",
       "      <th>logp_lhs_e1</th>\n",
       "      <th>logp_lhs_e2</th>\n",
       "      <th>logp_e1_lhs</th>\n",
       "      <th>logp_e2_lhs</th>\n",
       "      <th>logp_e1_e2</th>\n",
       "      <th>logp_e1_e2_lhs</th>\n",
       "      <th>logp_e2_e1</th>\n",
       "      <th>logp_e2_e1_lhs</th>\n",
       "      <th>AGigaSim</th>\n",
       "      <th>GoogleNgramSim</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.744950</td>\n",
       "      <td>4.76476</td>\n",
       "      <td>0.435509</td>\n",
       "      <td>0.232661</td>\n",
       "      <td>-0.946388</td>\n",
       "      <td>0.228995</td>\n",
       "      <td>0.914758</td>\n",
       "      <td>-0.03176</td>\n",
       "      <td>0.435317</td>\n",
       "      <td>-1.280009</td>\n",
       "      <td>-0.624575</td>\n",
       "      <td>0.894714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>24.046320</td>\n",
       "      <td>4.68897</td>\n",
       "      <td>0.531890</td>\n",
       "      <td>0.052497</td>\n",
       "      <td>-0.561156</td>\n",
       "      <td>1.401802</td>\n",
       "      <td>0.440235</td>\n",
       "      <td>0.33699</td>\n",
       "      <td>0.173777</td>\n",
       "      <td>-0.029438</td>\n",
       "      <td>2.251837</td>\n",
       "      <td>-0.127533</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_type ppdb1_score ppdb2_score  logp_lhs_e1  logp_lhs_e2  logp_e1_lhs  \\\n",
       "0        0.0   12.744950     4.76476     0.435509     0.232661    -0.946388   \n",
       "1        1.0   24.046320     4.68897     0.531890     0.052497    -0.561156   \n",
       "\n",
       "   logp_e2_lhs  logp_e1_e2  logp_e1_e2_lhs  logp_e2_e1  logp_e2_e1_lhs  \\\n",
       "0     0.228995    0.914758        -0.03176    0.435317       -1.280009   \n",
       "1     1.401802    0.440235         0.33699    0.173777       -0.029438   \n",
       "\n",
       "   AGigaSim  GoogleNgramSim  result  \n",
       "0 -0.624575        0.894714     0.0  \n",
       "1  2.251837       -0.127533     1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extracting features from the csv\n",
    "\n",
    "for index,element in enumerate(ppdb_train_data[4]):\n",
    "    logp_lhs_e1 = element.split('=')[1].split(' ')[0]\n",
    "    train_data.loc[index, \"logp_lhs_e1\"] = logp_lhs_e1\n",
    "\n",
    "for index,element in enumerate(ppdb_train_data[5]):\n",
    "    logp_lhs_e2 = element.split('=')[1].split(' ')[0]\n",
    "    train_data.loc[index, \"logp_lhs_e2\"] = logp_lhs_e2\n",
    "    \n",
    "for index,element in enumerate(ppdb_train_data[6]):\n",
    "    logp_e1_lhs = element.split('=')[1].split(' ')[0]\n",
    "    train_data.loc[index, \"logp_e1_lhs\"] = logp_e1_lhs\n",
    "    \n",
    "for index,element in enumerate(ppdb_train_data[7]):\n",
    "    logp_e1_e2 = element.split('=')[1].split(' ')[0]\n",
    "    train_data.loc[index, \"logp_e1_e2\"] = logp_e1_e2\n",
    "\n",
    "for index,element in enumerate(ppdb_train_data[8]):\n",
    "    logp_e1_e2_lhs = element.split('=')[1].split(' ')[0]\n",
    "    train_data.loc[index, \"logp_e1_e2_lhs\"] = logp_e1_e2_lhs\n",
    "    \n",
    "for index,element in enumerate(ppdb_train_data[9]):\n",
    "    logp_e2_lhs = element.split('=')[1].split(' ')[0]\n",
    "    train_data.loc[index, \"logp_e2_lhs\"] = logp_e2_lhs\n",
    "    \n",
    "for index,element in enumerate(ppdb_train_data[10]):\n",
    "    logp_e2_e1 = element.split('=')[1].split(' ')[0]\n",
    "    train_data.loc[index, \"logp_e2_e1\"] = logp_e2_e1\n",
    "\n",
    "for index,element in enumerate(ppdb_train_data[11]):\n",
    "    logp_e2_e1_lhs = element.split('=')[1].split(' ')[0]\n",
    "    train_data.loc[index, \"logp_e2_e1_lhs\"] = logp_e2_e1_lhs\n",
    "\n",
    "for index,element in enumerate(ppdb_train_data[11]):\n",
    "    AGigaSim = element.split('=')[2].split(' ')[0]\n",
    "    train_data.loc[index, \"AGigaSim\"] = AGigaSim\n",
    "\n",
    "for index,element in enumerate(ppdb_train_data[11]):\n",
    "    GoogleNgramSim = element.split('=')[11].split(' ')[0]\n",
    "    train_data.loc[index, \"GoogleNgramSim\"] = GoogleNgramSim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ppdb1_score</th>\n",
       "      <th>ppdb2_score</th>\n",
       "      <th>logp_lhs_e1</th>\n",
       "      <th>logp_lhs_e2</th>\n",
       "      <th>logp_e1_lhs</th>\n",
       "      <th>logp_e2_lhs</th>\n",
       "      <th>logp_e1_e2</th>\n",
       "      <th>logp_e1_e2_lhs</th>\n",
       "      <th>logp_e2_e1</th>\n",
       "      <th>logp_e2_e1_lhs</th>\n",
       "      <th>AGigaSim</th>\n",
       "      <th>GoogleNgramSim</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.744950</td>\n",
       "      <td>4.76476</td>\n",
       "      <td>0.30786</td>\n",
       "      <td>0.89456</td>\n",
       "      <td>14.95995</td>\n",
       "      <td>12.48692</td>\n",
       "      <td>7.90234</td>\n",
       "      <td>6.75647</td>\n",
       "      <td>4.84261</td>\n",
       "      <td>4.28343</td>\n",
       "      <td>0.80561</td>\n",
       "      <td>0.33742</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>24.046320</td>\n",
       "      <td>4.68897</td>\n",
       "      <td>0.15099</td>\n",
       "      <td>1.28093</td>\n",
       "      <td>11.88724</td>\n",
       "      <td>14.59836</td>\n",
       "      <td>11.23257</td>\n",
       "      <td>7.19074</td>\n",
       "      <td>12.81375</td>\n",
       "      <td>9.90186</td>\n",
       "      <td>0.53500</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_type ppdb1_score ppdb2_score logp_lhs_e1 logp_lhs_e2 logp_e1_lhs  \\\n",
       "0        0.0   12.744950     4.76476     0.30786     0.89456    14.95995   \n",
       "1        1.0   24.046320     4.68897     0.15099     1.28093    11.88724   \n",
       "\n",
       "  logp_e2_lhs logp_e1_e2 logp_e1_e2_lhs logp_e2_e1 logp_e2_e1_lhs AGigaSim  \\\n",
       "0    12.48692    7.90234        6.75647    4.84261        4.28343  0.80561   \n",
       "1    14.59836   11.23257        7.19074   12.81375        9.90186  0.53500   \n",
       "\n",
       "  GoogleNgramSim  result  \n",
       "0        0.33742     0.0  \n",
       "1              0     1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.424995227564\n"
     ]
    }
   ],
   "source": [
    "## Implementing a random forest ##\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#using only the features to be used for training\n",
    "features = [column for column in columns if column is not \"result\"]\n",
    "\n",
    "# Initialize our algorithm with the default paramters\n",
    "# n_estimators is the number of trees we want to make\n",
    "# min_samples_split is the minimum number of rows we need to make a split\n",
    "# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, min_samples_leaf=1)\n",
    "scores = cross_validation.cross_val_score(alg, train_data[features],train_data[\"result\"],cv=3).mean()\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "* Try out different classical methods of classification : https://github.com/nitish11/Kaggle-submissions/blob/master/red-hat-business-value_train.py\n",
    "* Hyper parameter tuning for different algorithm \n",
    "* Ensemble method : to use combination of algorithms for classification \n",
    "* Adding more features from CSV\n",
    "* Selecting best features from training data \"Feature Selection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
